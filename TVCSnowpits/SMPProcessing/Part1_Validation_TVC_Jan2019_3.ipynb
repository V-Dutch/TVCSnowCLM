{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment of SMP and Snow Pits / Evaluation of Proksch (P15) coefficients\n",
    "*Josh King, Environment and Climate Change Canada, 2019*\n",
    "\n",
    "This workbook introduces a snow on sea ice calibration procedure for SMP-derived estimates of density first introduced in [Proksch, et al., 2015](https://agupubs.onlinelibrary.wiley.com/doi/10.1002/2014JF003266). Where indicated, the work modifies portions of the [SMP python package from SLF](https://github.com/slf-dot-ch/snowmicropyn) and uses a number of open source community packages to facilitate processing.\n",
    "\n",
    "I'm still not great at GIS in python so the maps in the publication were done in ESRI ArcMap.\n",
    "\n",
    "### ***Alignment takes a long time due to the large number of scaling candidates. If you want to skip that part and just load the result set, set `skip_alignment` below to `True`.***\n",
    "\n",
    "### Notes on settings and constants\n",
    "**CUTTER_SIZE** defines the half height in mm of the density cutter used as reference. Can be changed to accommodate different sampler sizes. No need to change this for ECCC data. \n",
    "\n",
    "**WINDOW_SIZE** defines the size of the rolling window used in SLF shot noise calculations. A 5 mm window was used in [Proksch, et al., 2015](https://agupubs.onlinelibrary.wiley.com/doi/10.1002/2014JF003266) when there was separation between the SMP and density cutter. Increasing the window reduces sensitivity to sharp transitions and reduces resolution of the analysis. However, moving to something like 2.5 mm makes comparison difficult as some of the very fine structure resolved as very different over the ~10 cm separation between the SMP and density profiles. \n",
    "\n",
    "**NUM_TESTS** defines how many random scaling configurations to test against when attempting to align the SMP and snow pit data. We brute-force the alignment in our paper so `NUM_TESTS` must be large to ensure the test space searched is sufficient. A lower number of tests risks poor alignment and therefore poor calibration. In the paper we use 10k permutations.\n",
    "\n",
    "**MAX_STRETCH_LAYER** and **MAX_STRETCH_OVERALL** define how much an individual layer can be eroded or dilated, and the maximum change in total length of the SMP profile, respectively. We allow a rather large 70% change to individual layers to accommodate pinching out but restrict the total change to 10% to avoid overfitting.\n",
    "\n",
    "**H_RESAMPLE** and **L_RESAMPLE** define the resampled resolution of the SMP and the layer size used for matching profiles. These terms are interactive with the layer stretching and should be evaluated carefully if changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community packages\n",
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "\n",
    "# Local packages\n",
    "import smpfunc # SMP helper functions\n",
    "\n",
    "# Import SLF SMP Package\n",
    "from snowmicropyn import Profile, proksch2015, loewe2012\n",
    "\n",
    "# Set constants\n",
    "CUTTER_SIZE = 15  # Half the height of the density cutter in mm\n",
    "# Have calculated cutter size from density profile measurements\n",
    "WINDOW_SIZE = 5  # SMP analysis window in mm\n",
    "H_RESAMPLE = 1  # Delta height in mm for standardized SMP profiles\n",
    "L_RESAMPLE = 50  # Layer unit height in mm for SMP matching\n",
    "MAX_STRETCH_LAYER = 0.75  # Max layer change in % of height\n",
    "MAX_STRETCH_OVERALL = 0.15  # Max profile change in % of total height\n",
    "NUM_TESTS = 10000  # Number of scaling candidates to generate for alignment testing \n",
    "\n",
    "# Set conditions\n",
    "skip_alignment = False # Set as true to just load the results from a pickle instead of reprocessing\n",
    "paper_conditions = True # Set as true to reproduce the paper results with seeding\n",
    "\n",
    "# Small differences in comparison to the paper will occur if a seed is not set.\n",
    "# This is mainly because we use a brute-force approach to matching the smp and \n",
    "# snow pit profiles with modest search size (specified by NUM_TESTS).\n",
    "if paper_conditions:\n",
    "    np.random.seed(2019) \n",
    "\n",
    "os.makedirs('./output/figures', exist_ok=True)    \n",
    "    \n",
    "def rmse(data):\n",
    "    return np.sqrt(np.mean(data**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mat73\n",
    "\n",
    "# Replace Josh's pit_density with Vicki's\n",
    "TVC = mat73.loadmat('./data/TVC_Jan2019/TVC_Jan2019_.mat')\n",
    "# Redefine upper level of structure (avoids text evaluation problem caused by ['TVC'])\n",
    "\n",
    "tvc = TVC['TVC_Jan2019']\n",
    "\n",
    "# Get list of pit names\n",
    "pit_list = list(tvc.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file showing nearest SMP profile to pits\n",
    "nearest_smp = pd.read_excel('./data/TVC_Jan2019/NearestNeighbourSMP_3.xlsx', index_col='Pit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nearest_smp(pit):\n",
    "    # Looks up nearest smp profile to pits from excel file, returns nan if not available\n",
    "    try:\n",
    "        return nearest_smp.loc[pit]['Nearest Neighbour SMP']\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "def get_nearest_smp_data(pit):\n",
    "    # Returns SMP data closest to pit, or NaN if not available\n",
    "    if type(get_nearest_smp(pit)) == str:\n",
    "        return pd.DataFrame(eval('tvc.' + pit + '.SMP.CroppedProfiles.' + get_nearest_smp(pit)), columns={'depth_smp', 'force'}).rename(columns={'depth_smp':'distance'})\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pull out single pit data from .mat file and put in pandas dataframe\n",
    "def get_pit_density_data(pit):\n",
    "    # Make dictionary\n",
    "    obs = {'id': [pit] * len(tvc[pit].density.densityA), 'density': tvc[pit].density.densityA, \n",
    "           'top': tvc[pit].density.boundary_top, 'bottom': tvc[pit].density.boundary_btm}\n",
    "\n",
    "    return pd.DataFrame(obs, columns={'id', 'density', 'top', 'bottom'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract density data from all pits\n",
    "all_pits = [get_pit_density_data(p) for p in pit_list] # list of pandas dataframes\n",
    "\n",
    "# Join list of dataframes\n",
    "new_pit_density = pd.concat(all_pits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get grain type information for all layers\n",
    "def get_grain_types(pit):\n",
    "    #print(pit)\n",
    "    #Make dictionary\n",
    "    obs = {'id':[pit] * len(tvc[pit].stratigraphy_layers.grain_type), 'grain_type': tvc[pit].stratigraphy_layers.grain_type, 'strat_comment':tvc[pit].stratigraphy_layers.strat_comment,\n",
    "           'top': tvc[pit].stratigraphy_layers.strat_top, 'bottom':tvc[pit].stratigraphy_layers.strat_btm}\n",
    "    \n",
    "    return pd.DataFrame(obs, columns={'id', 'grain_type', 'strat_comment', 'top', 'bottom'}) #dataframe currently contains strat_comment in cell format as python does not recognise matlab string arrays. this is creating problems with trying to search what the string says. \n",
    "\n",
    "all_pits_ = [get_grain_types(p) for p in pit_list] #list of dataframes > assuming needs to not be called \"all_pits\" so python doesn't get confused, but as obs is re-written anyway, name can stay the same?\n",
    "\n",
    "# Join list of dataframes\n",
    "grain_types_pits = pd.concat(all_pits_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grains = []\n",
    "# Grain type for each layer is its own list\n",
    "# Make extract these into a single list, change letters and put back into grain_types_pits \n",
    "for val in grain_types_pits.grain_type:\n",
    "    grains.append(val[0])\n",
    "\n",
    "# Switch to upper case\n",
    "# https://stackoverflow.com/questions/1801668/convert-a-python-list-with-strings-all-to-lowercase-or-uppercase\n",
    "grains = [x.upper() for x in grains]\n",
    "# Replace M -> N\n",
    "# https://stackoverflow.com/questions/2582138/finding-and-replacing-elements-in-a-list\n",
    "grains = ['N' if x == 'M' else x for x in grains]\n",
    "# Replace C -> I \n",
    "# C denotes layers containing crusts, so do not want to include these layers in the calibration, but this'll come later\n",
    "grains = ['I' if x == 'C' else x for x in grains]\n",
    "\n",
    "\n",
    "# ^^ I MADE A NEW COLUMN SO YOU CAN SEE DIFFERENCE BETWEEN FORMATS OF GRAIN_TYPE AND NEW_GRAIN_TYPE\n",
    "# IF YOU WANT TO OVERWRITE grain_type JUST DELETE THE ONE ABOVE AND UNCOMMENT ONE BELOW > Thanks, Done :)\n",
    "\n",
    "grain_types_pits['grain_type'] = grains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bottom     id  density   top TYPE\n",
      "0     47.0  RP_01    242.0  50.0    N\n",
      "1     44.0  RP_01    221.0  47.0    N\n",
      "2     41.0  RP_01    153.0  44.0    N\n",
      "3     38.0  RP_01    371.0  41.0    F\n",
      "4     35.0  RP_01    385.0  38.0    F\n",
      "..     ...    ...      ...   ...  ...\n",
      "2     19.0  SV_02    408.0  22.0    N\n",
      "3     16.0  SV_02    365.0  19.0    F\n",
      "4     13.0  SV_02    296.0  16.0    F\n",
      "5     10.0  SV_02    223.0  13.0    F\n",
      "6      7.0  SV_02    223.0  10.0    F\n",
      "\n",
      "[273 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create list of grain types at resolution of density info\n",
    "new_pit_density = new_pit_density.assign(TYPE = 'R') # initally all rounds, will overwrite to include other grain types\n",
    "\n",
    "# Set others depending on whatever condition\n",
    "# https://stackoverflow.com/questions/15315452/selecting-with-complex-criteria-from-pandas-dataframe\n",
    "\n",
    "# Created new copy of notebook for each campaign so easy to re-write this cell for different campaigns\n",
    "\n",
    "#Set Faceted Grains\n",
    "new_pit_density.loc[(new_pit_density.top<=43) & (new_pit_density.id=='RP_01'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=35) & (new_pit_density.id=='RP_02'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=27) & (new_pit_density.id=='RP_03'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=18) & (new_pit_density.id=='RP_04'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=35) & (new_pit_density.id=='RP_05'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=20) & (new_pit_density.id=='RP_06'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=29) & (new_pit_density.id=='RP_07'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=29) & (new_pit_density.id=='RP_08'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=44) & (new_pit_density.id=='RP_09'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=28) & (new_pit_density.id=='RP_10'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=20) & (new_pit_density.id=='RP_11'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=35) & (new_pit_density.id=='RP_12'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=35) & (new_pit_density.id=='RP_13'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=21) & (new_pit_density.id=='RP_14'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=35) & (new_pit_density.id=='RP_15'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=35) & (new_pit_density.id=='RP_16'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=34) & (new_pit_density.id=='RP_17'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=15) & (new_pit_density.id=='RP_18'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=20) & (new_pit_density.id=='SC_02'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=42) & (new_pit_density.id=='SD_02'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=32) & (new_pit_density.id=='SM_02'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=22) & (new_pit_density.id=='SO_02'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=45) & (new_pit_density.id=='SR_02'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=21) & (new_pit_density.id=='ST_02'), 'TYPE']='F'\n",
    "new_pit_density.loc[(new_pit_density.top<=22) & (new_pit_density.id=='SV_02'), 'TYPE']='F'\n",
    "\n",
    "#Set New Snow\n",
    "new_pit_density.loc[(new_pit_density.top>=43) & (new_pit_density.id=='RP_01'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=35) & (new_pit_density.id=='RP_02'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=27) & (new_pit_density.id=='RP_03'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=18) & (new_pit_density.id=='RP_04'), 'TYPE']='N' #Type set as N not R, but description of \"faceting wind rounds\"\n",
    "new_pit_density.loc[(new_pit_density.top>=35) & (new_pit_density.id=='RP_05'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=20) & (new_pit_density.id=='RP_06'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=29) & (new_pit_density.id=='RP_07'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=29) & (new_pit_density.id=='RP_08'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=44) & (new_pit_density.id=='RP_09'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=28) & (new_pit_density.id=='RP_10'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=20) & (new_pit_density.id=='RP_11'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=35) & (new_pit_density.id=='RP_12'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=35) & (new_pit_density.id=='RP_13'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=21) & (new_pit_density.id=='RP_14'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=35) & (new_pit_density.id=='RP_15'), 'TYPE']='N' #Type set as N not R but description is of \"faceting wind rounds\"\n",
    "new_pit_density.loc[(new_pit_density.top>=35) & (new_pit_density.id=='RP_16'), 'TYPE']='N' #Type set as N not R but description is of \"faceting wind rounds\"\n",
    "new_pit_density.loc[(new_pit_density.top>=34) & (new_pit_density.id=='RP_17'), 'TYPE']='N'\n",
    "# No new snow for RP_18\n",
    "new_pit_density.loc[(new_pit_density.top>=20) & (new_pit_density.id=='SC_02'), 'TYPE']='N'\n",
    "# Pit SD_02 describes New snow below layer of rounds > assume errounous and leave for now\n",
    "new_pit_density.loc[(new_pit_density.top>=33) & (new_pit_density.id=='SM_02'), 'TYPE']='N' #Double check, strat_comment looks odd\n",
    "new_pit_density.loc[(new_pit_density.top>=22) & (new_pit_density.id=='SO_02'), 'TYPE']='N' #Type set as N not R but description is of \"faceting wind rounds\"\n",
    "new_pit_density.loc[(new_pit_density.top>=45) & (new_pit_density.id=='SR_02'), 'TYPE']='N'\n",
    "new_pit_density.loc[(new_pit_density.top>=21) & (new_pit_density.id=='ST_02'), 'TYPE']='N' #Type set as N not R but description is of \"faceting wind rounds\"\n",
    "new_pit_density.loc[(new_pit_density.top>=22) & (new_pit_density.id=='SV_02'), 'TYPE']='N'\n",
    "\n",
    "#Print to check worked\n",
    "\n",
    "print(new_pit_density) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Josh splits F (faceted) into F and D (Depth Hoar), which source data does not do. \n",
    "# Starting point is if strat_comment mentions depth hoar, convert manually as above\n",
    "#(Considered using some sort of loop, but as had to do Facted grains manually and would have to convert to regular expressions, I'm not convinved it's worth it)\n",
    "\n",
    "# Rule: F becomes D if \"strat_comment\" mentions \"Depth Hoar\" or \"Hoar\" (or a typo clearly meant to be one of these), BUT NOT \"Indurated Hoar\" or \"Hoar Parting\"\n",
    "\n",
    "#Set Depth Hoar\n",
    "new_pit_density.loc[(new_pit_density.top<=27) & (new_pit_density.id=='RP_01'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=18) & (new_pit_density.id=='RP_02'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=18) & (new_pit_density.id=='RP_03'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=13) & (new_pit_density.id=='RP_04'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=29) & (new_pit_density.id=='RP_05'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=18) & (new_pit_density.id=='RP_06'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=23) & (new_pit_density.id=='RP_07'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=29) & (new_pit_density.id=='RP_08'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=23) & (new_pit_density.id=='RP_09'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=18) & (new_pit_density.id=='RP_10'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=20) & (new_pit_density.id=='RP_11'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=28) & (new_pit_density.id=='RP_12'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=25) & (new_pit_density.id=='RP_13'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=19) & (new_pit_density.id=='RP_14'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=16) & (new_pit_density.id=='RP_15'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=25) & (new_pit_density.id=='RP_16'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=22) & (new_pit_density.id=='RP_17'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=15) & (new_pit_density.id=='RP_18'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=17) & (new_pit_density.id=='SC_02'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=25) & (new_pit_density.id=='SD_02'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=32) & (new_pit_density.id=='SM_02'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=17) & (new_pit_density.id=='SO_02'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=21) & (new_pit_density.id=='SR_02'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=21) & (new_pit_density.id=='ST_02'), 'TYPE']='D'\n",
    "new_pit_density.loc[(new_pit_density.top<=12) & (new_pit_density.id=='SV_02'), 'TYPE']='D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function 2: Find location of ice lenses\n",
    "\n",
    "# Set layers containing ice as above:\n",
    "# NO Surface crusts unlike March, probably because earlier in the season and snow continuing to accumulate, not much sunlight avalible to cause them to form. \n",
    "\n",
    "# Set remaining ice crusts, having manually identified which density layers they belong to:\n",
    "new_pit_density.loc[(new_pit_density.top==22)& (new_pit_density.id=='RP_02'), 'TYPE']='I'# Faceted crust at 20cm\n",
    "new_pit_density.loc[(new_pit_density.top==20)& (new_pit_density.id=='RP_03'), 'TYPE']='I'# Faceted crust at 20cm\n",
    "new_pit_density.loc[(new_pit_density.top==17)& (new_pit_density.id=='RP_04'), 'TYPE']='I'# Facted crust at 15.5cm\n",
    "new_pit_density.loc[(new_pit_density.top==29)& (new_pit_density.id=='RP_07'), 'TYPE']='I'# Faceted crust at 27cm\n",
    "new_pit_density.loc[(new_pit_density.top==22)& (new_pit_density.id=='RP_14'), 'TYPE']='I'# Faceted crust at 20cm\n",
    "new_pit_density.loc[(new_pit_density.top==27)& (new_pit_density.id=='RP_16'), 'TYPE']='I'# Faceted crust at 27cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bottom</th>\n",
       "      <th>id</th>\n",
       "      <th>density</th>\n",
       "      <th>top</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>242.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>221.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>153.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>371.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>385.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>367.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>29.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>262.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>232.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>230.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>241.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>219.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>233.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>224.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>228.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>224.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>226.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>276.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>265.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>390.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>381.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>369.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>22.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>317.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>208.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>206.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>212.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>210.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.0</td>\n",
       "      <td>RP_02</td>\n",
       "      <td>212.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35.0</td>\n",
       "      <td>RP_03</td>\n",
       "      <td>363.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.0</td>\n",
       "      <td>RP_03</td>\n",
       "      <td>382.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.0</td>\n",
       "      <td>RP_03</td>\n",
       "      <td>383.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>365.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>369.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>400.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>249.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>247.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>24.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>239.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>290.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>18.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>290.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>287.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>290.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>9.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>271.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>307.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.0</td>\n",
       "      <td>SR_02</td>\n",
       "      <td>308.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.0</td>\n",
       "      <td>ST_02</td>\n",
       "      <td>435.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>ST_02</td>\n",
       "      <td>413.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22.0</td>\n",
       "      <td>ST_02</td>\n",
       "      <td>379.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.0</td>\n",
       "      <td>ST_02</td>\n",
       "      <td>227.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.0</td>\n",
       "      <td>ST_02</td>\n",
       "      <td>209.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.0</td>\n",
       "      <td>ST_02</td>\n",
       "      <td>216.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10.0</td>\n",
       "      <td>ST_02</td>\n",
       "      <td>229.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>ST_02</td>\n",
       "      <td>230.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>ST_02</td>\n",
       "      <td>217.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>ST_02</td>\n",
       "      <td>244.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.0</td>\n",
       "      <td>SV_02</td>\n",
       "      <td>267.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22.0</td>\n",
       "      <td>SV_02</td>\n",
       "      <td>192.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.0</td>\n",
       "      <td>SV_02</td>\n",
       "      <td>408.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>SV_02</td>\n",
       "      <td>365.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>SV_02</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>SV_02</td>\n",
       "      <td>223.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>SV_02</td>\n",
       "      <td>223.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    bottom     id  density   top TYPE\n",
       "0     47.0  RP_01    242.0  50.0    N\n",
       "1     44.0  RP_01    221.0  47.0    N\n",
       "2     41.0  RP_01    153.0  44.0    N\n",
       "3     38.0  RP_01    371.0  41.0    F\n",
       "4     35.0  RP_01    385.0  38.0    F\n",
       "..     ...    ...      ...   ...  ...\n",
       "2     19.0  SV_02    408.0  22.0    N\n",
       "3     16.0  SV_02    365.0  19.0    F\n",
       "4     13.0  SV_02    296.0  16.0    F\n",
       "5     10.0  SV_02    223.0  13.0    F\n",
       "6      7.0  SV_02    223.0  10.0    D\n",
       "\n",
       "[273 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print to check works\n",
    "new_pit_density  \n",
    "\n",
    "#Leave removal of ice type layers until after comparison_df, in order to check fit of SMPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP_01\n",
      "RP_02\n",
      "RP_06\n",
      "RP_08\n",
      "RP_09\n",
      "RP_10\n",
      "RP_12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\snowmicropyn\\loewe2012.py:58: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  delta = -(3. / 2) * c_f[n - 1] / (c_f[n] - c_f[n - 1]) * spatial_res\n",
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\snowmicropyn\\loewe2012.py:61: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  lambda_ = (4. / 3) * (k1 ** 2) / k2 / delta  # Intensity\n",
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\snowmicropyn\\loewe2012.py:62: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f0 = (3. / 2) * k2 / k1\n",
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\snowmicropyn\\proksch2015.py:39: RuntimeWarning: divide by zero encountered in log\n",
      "  density = a1 + a2 * np.log(fm) + a3 * np.log(fm) * l + a4 * l\n",
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\snowmicropyn\\proksch2015.py:39: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  density = a1 + a2 * np.log(fm) + a3 * np.log(fm) * l + a4 * l\n",
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\snowmicropyn\\proksch2015.py:45: RuntimeWarning: divide by zero encountered in log\n",
      "  lc = c1 + c2 * l + c3 * np.log(fm)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP_13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3118: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\numpy\\core\\_methods.py:85: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\numpy\\core\\_methods.py:140: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\numpy\\core\\_methods.py:110: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\numpy\\core\\_methods.py:132: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RP_15\n",
      "RP_16\n",
      "RP_17\n",
      "RP_18\n",
      "SD_02\n",
      "SO_02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\snowmicropyn\\loewe2012.py:61: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  lambda_ = (4. / 3) * (k1 ** 2) / k2 / delta  # Intensity\n",
      "C:\\Users\\vicki\\Anaconda\\envs\\smp-sea-ice\\lib\\site-packages\\numpy\\lib\\function_base.py:3405: RuntimeWarning: Invalid value encountered in median\n",
      "  r = func(a, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SR_02\n",
      "ST_02\n"
     ]
    }
   ],
   "source": [
    "# It's all about generating the comparison_df\n",
    "comparison_df = pd.DataFrame()\n",
    "min_scaling_coeff = []\n",
    "all_smp_df = pd.DataFrame()\n",
    "\n",
    "# Loop over pits\n",
    "for p in pit_list:\n",
    "    # Extract smp data for profile nearest to snowpit\n",
    "    nearest_smp_profile = get_nearest_smp_data(p)\n",
    "    # Only pick out pits with nearest smp\n",
    "    # Will ignore pits that return NaN (not a pandas dataframe) for get_nearest_smp_data\n",
    "    if isinstance(nearest_smp_profile, pd.DataFrame):\n",
    "        # Get density data\n",
    "        density_df = new_pit_density[new_pit_density.id == p].rename(columns={'density': 'RHO'})\n",
    "        # Add in relative height\n",
    "        # Think this is defined as distance of layer midpoint from surface, in mm\n",
    "        cutter_size = float(stats.mode(density_df.top.iloc[0] - density_df.bottom).mode) \n",
    "        density_df = density_df.assign(relative_height_mm = (density_df.top[0] - density_df.bottom - cutter_size / 2) * 10)\n",
    "        \n",
    "        # Linear interpolation of SMP data (so have no NaN values)\n",
    "        nearest_smp_profile = nearest_smp_profile.interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "        \n",
    "        print (p) # Tells you which profiles have numerical instabilities - can remove this statement later\n",
    "        # Make first guess at microstructure based on original profile\n",
    "        l2012 = loewe2012.calc(nearest_smp_profile, window=WINDOW_SIZE)\n",
    "        p2015 = proksch2015.calc(nearest_smp_profile, window=WINDOW_SIZE)\n",
    "        \n",
    "        smp_profile_height = p2015.distance.max() # This in mm\n",
    "        # I have used the snow depth from this snow pit. Josh has used mean of magnaprobe depths\n",
    "        # To get mean of magnaprobe depths, you can use tvc[p].magnaprobe.MgP_Summary.Mean_MgPDepth\n",
    "        # If SMP height is less than snowpack height, no need to shorten profile\n",
    "        smp_height_diff = min(0, density_df.top.iloc[0] * 10 - smp_profile_height) \n",
    "        \n",
    "        # Create new SMP resampled arrays and determine the number of layers\n",
    "        depth_array = np.arange(0, p2015.distance.max() + smp_height_diff, H_RESAMPLE)\n",
    "        density_array = np.interp(depth_array,p2015.distance,p2015.P2015_density)\n",
    "        force_array = np.interp(depth_array,p2015.distance,l2012.force_median)\n",
    "        l_array = np.interp(depth_array,p2015.distance,l2012.L2012_L)\n",
    "        id_array = p\n",
    "\n",
    "        smp_df = pd.DataFrame({'distance': depth_array, \n",
    "                               'density': density_array,\n",
    "                               'force_median': force_array,\n",
    "                               'l': l_array, \n",
    "                               'id':id_array,})\n",
    "        \n",
    "        all_smp_df = all_smp_df.append(smp_df)\n",
    "\n",
    "        # Generate a selection of random transformation to brute-force alignment\n",
    "        # We use this brute force approach because there was no gradient that could be used to optimize the relationship\n",
    "        num_sections = np.ceil(len(smp_df.index)/L_RESAMPLE).astype(int)\n",
    "        random_tests = [smpfunc.random_stretch(x, MAX_STRETCH_OVERALL, MAX_STRETCH_LAYER) for x in np.repeat(num_sections, NUM_TESTS)] \n",
    "\n",
    "        scaled_profiles = [smpfunc.scale_profile(test, smp_df.distance.values, smp_df.density.values, L_RESAMPLE, H_RESAMPLE) for test in random_tests]\n",
    "        compare_profiles = [smpfunc.extract_samples(dist, rho, density_df.relative_height_mm.values, cutter_size) for dist, rho in scaled_profiles]\n",
    "        compare_profiles = [pd.concat([profile, density_df.reset_index()], axis=1, sort=False) for profile in compare_profiles]\n",
    "        retrieved_skill = [smpfunc.calc_skill(profile, cutter_size) for profile in compare_profiles]\n",
    "        retrieved_skill = pd.DataFrame(retrieved_skill,columns = ['r','rmse','rmse_corr','mae'])\n",
    "\n",
    "        min_scaling_idx = retrieved_skill.sort_values(['r', 'rmse_corr'], ascending=[False, True]).head(1).index.values\n",
    "        min_scaling_coeff.append(random_tests[int(min_scaling_idx)])\n",
    "        \n",
    "        dist, scaled_l =  smpfunc.scale_profile(min_scaling_coeff[-1], smp_df.distance.values, smp_df.l.values, L_RESAMPLE, H_RESAMPLE)\n",
    "        dist, scaled_force_median = smpfunc.scale_profile(min_scaling_coeff[-1], smp_df.distance.values, smp_df.force_median.values, L_RESAMPLE, H_RESAMPLE)\n",
    "\n",
    "        result = compare_profiles[int(min_scaling_idx)].assign(l=smpfunc.extract_samples(dist, scaled_l, density_df.relative_height_mm.values, cutter_size).mean_samp,\n",
    "                                                  force_median=smpfunc.extract_samples(dist, scaled_force_median, density_df.relative_height_mm.values, cutter_size).mean_samp)\n",
    "        comparison_df = comparison_df.append(result, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a local file since tbe brute-force method takes a while to compute\n",
    "comparison_df.to_pickle(\"./output/TVC/TVC_Jan2019_smp_pit_comparison_3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     count_samp   mean_samp  median_samp  stdev_samp  index  bottom     id  \\\n",
      "0             7   22.598556    21.468414    4.066480      0    47.0  RP_01   \n",
      "1             7  398.596814   409.300656   19.569935      1    44.0  RP_01   \n",
      "2             7  225.770318   218.796716   39.438038      2    41.0  RP_01   \n",
      "3             7  568.917286   571.620733   10.750147      3    38.0  RP_01   \n",
      "4             7  542.346539   543.534441    3.679610      4    35.0  RP_01   \n",
      "..          ...         ...          ...         ...    ...     ...    ...   \n",
      "181           7  274.044944   274.206680    3.422400      5    13.0  ST_02   \n",
      "182           7  294.038296   290.799897   12.610278      6    10.0  ST_02   \n",
      "183           7  289.689438   291.275857    4.047493      7     7.0  ST_02   \n",
      "184           7  277.813520   277.221258    5.582478      8     4.0  ST_02   \n",
      "185           7  320.314389   279.025807   67.761575      9     1.0  ST_02   \n",
      "\n",
      "       RHO   top TYPE  relative_height_mm         l  force_median  \n",
      "0    242.0  50.0    N                15.0  0.175196      0.010784  \n",
      "1    221.0  47.0    N                45.0  0.097293      0.955946  \n",
      "2    153.0  44.0    N                75.0  0.189657      0.457522  \n",
      "3    371.0  41.0    F               105.0  0.150041      7.867569  \n",
      "4    385.0  38.0    F               135.0  0.174863      6.479529  \n",
      "..     ...   ...  ...                 ...       ...           ...  \n",
      "181  216.0  16.0    D               165.0  0.799217      0.158440  \n",
      "182  229.0  13.0    D               195.0  1.081098      0.151413  \n",
      "183  230.0  10.0    D               225.0  1.175670      0.179545  \n",
      "184  217.0   7.0    D               255.0  0.888612      0.354952  \n",
      "185  244.0   4.0    D               285.0  1.364190      0.197436  \n",
      "\n",
      "[186 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "# Save to .csv file so I can check it out in matlab\n",
    "\n",
    "print(comparison_df)\n",
    "\n",
    "comparison_df.to_csv('./output/TVC/TVC_Jan2019_comparison_3.csv',na_rep='NaN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     distance     density  force_median         l     id\n",
      "0         0.0  306.719758      0.011839  0.927453  RP_01\n",
      "1         1.0  288.331933      0.011839  0.877419  RP_01\n",
      "2         2.0  269.944107      0.011839  0.827384  RP_01\n",
      "3         3.0  211.403412      0.011576  0.673434  RP_01\n",
      "4         4.0  112.709846      0.011050  0.415566  RP_01\n",
      "..        ...         ...           ...       ...    ...\n",
      "305     305.0  264.526087      0.350569  1.129490  ST_02\n",
      "306     306.0  263.529362      0.361092  1.129527  ST_02\n",
      "307     307.0  262.532638      0.371616  1.129565  ST_02\n",
      "308     308.0  269.555052      0.431337  1.033851  ST_02\n",
      "309     309.0  284.596606      0.540257  0.842387  ST_02\n",
      "\n",
      "[6276 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(all_smp_df) # smp_df rewrites for each pit, so need to collate\n",
    "\n",
    "all_smp_df.to_csv('./output/TVC/TVC_Jan2019_allsmpdf_3.csv',na_rep='NaN') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_samp</th>\n",
       "      <th>mean_samp</th>\n",
       "      <th>median_samp</th>\n",
       "      <th>stdev_samp</th>\n",
       "      <th>index</th>\n",
       "      <th>bottom</th>\n",
       "      <th>id</th>\n",
       "      <th>RHO</th>\n",
       "      <th>top</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>relative_height_mm</th>\n",
       "      <th>l</th>\n",
       "      <th>force_median</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>22.598556</td>\n",
       "      <td>21.468414</td>\n",
       "      <td>4.066480</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>242.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>N</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.175196</td>\n",
       "      <td>0.010784</td>\n",
       "      <td>-219.401444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>398.596814</td>\n",
       "      <td>409.300656</td>\n",
       "      <td>19.569935</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>221.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>N</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.097293</td>\n",
       "      <td>0.955946</td>\n",
       "      <td>177.596814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>225.770318</td>\n",
       "      <td>218.796716</td>\n",
       "      <td>39.438038</td>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>153.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>N</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.189657</td>\n",
       "      <td>0.457522</td>\n",
       "      <td>72.770318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>568.917286</td>\n",
       "      <td>571.620733</td>\n",
       "      <td>10.750147</td>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>371.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>F</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.150041</td>\n",
       "      <td>7.867569</td>\n",
       "      <td>197.917286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>542.346539</td>\n",
       "      <td>543.534441</td>\n",
       "      <td>3.679610</td>\n",
       "      <td>4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>RP_01</td>\n",
       "      <td>385.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>F</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.174863</td>\n",
       "      <td>6.479529</td>\n",
       "      <td>157.346539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_samp   mean_samp  median_samp  stdev_samp  index  bottom     id  \\\n",
       "0           7   22.598556    21.468414    4.066480      0    47.0  RP_01   \n",
       "1           7  398.596814   409.300656   19.569935      1    44.0  RP_01   \n",
       "2           7  225.770318   218.796716   39.438038      2    41.0  RP_01   \n",
       "3           7  568.917286   571.620733   10.750147      3    38.0  RP_01   \n",
       "4           7  542.346539   543.534441    3.679610      4    35.0  RP_01   \n",
       "\n",
       "     RHO   top TYPE  relative_height_mm         l  force_median       error  \n",
       "0  242.0  50.0    N                15.0  0.175196      0.010784 -219.401444  \n",
       "1  221.0  47.0    N                45.0  0.097293      0.955946  177.596814  \n",
       "2  153.0  44.0    N                75.0  0.189657      0.457522   72.770318  \n",
       "3  371.0  41.0    F               105.0  0.150041      7.867569  197.917286  \n",
       "4  385.0  38.0    F               135.0  0.174863      6.479529  157.346539  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filter results\n",
    "result = comparison_df.dropna() #All NaNs should already have been removed, but just in case\n",
    "result = result[result['count_samp']>=cutter_size*2] # Remove comparisons outside the profile\n",
    "#result = result[~result['TYPE'].isin(['N', 'I'])] # Remove new snow and ice because we don't have enough samples\n",
    "result = result[~result['TYPE'].isin(['I'])] # Alternate option, only remove ice layers because of high number of new snow samples as January is still in the middle of the snow season\n",
    "result['error'] = result['mean_samp']-result['RHO']\n",
    "result.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proksch et al. 2015 Eval.\n",
      "N: 185\n",
      "RMSE: 128.0\n",
      "bias: 99.0\n",
      "r^2: 0.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TYPE\n",
       "D     77.256530\n",
       "F    139.926481\n",
       "N    179.147614\n",
       "R    148.296373\n",
       "Name: error, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compare manual density cutter measurements and SMP-derived densities\n",
    "# P2015 evaluation stats\n",
    "p2015_rmse = np.sqrt(np.mean(result['error']**2))\n",
    "p2015_bias = (result['error']).mean()\n",
    "p2015_r2 = np.ma.corrcoef(result['mean_samp'],result['RHO'])[0, 1]**2\n",
    "p2015_n = len(result['mean_samp'])\n",
    "p2015_p = stats.pearsonr(result['mean_samp'],result['RHO'])[1]\n",
    "\n",
    "print('Proksch et al. 2015 Eval.')\n",
    "print('N: %i' % p2015_n)\n",
    "print('RMSE: %0.1f' % np.round(p2015_rmse))\n",
    "print('bias: %0.1f' % np.round(p2015_bias))\n",
    "print('r^2: %0.2f' % p2015_r2)\n",
    "\n",
    "# Error as a % of mean density\n",
    "np.round(rmse(result.error)/ result['RHO'].mean(),2)\n",
    "\n",
    "# RMSE by layer type\n",
    "result.groupby('TYPE')['error'].apply(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the dataset\n",
    "result.to_pickle(\"./output/TVC/TVC_Jan2019_smp_pit_filtered_incN_3.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
